---
title: "[Competition] 2017 Big Contest"
layout: post
date: 2018-01-19
tag:
- competition
- bigcontest
- loan
- ML
category: project
projects: true
author: sang-hyeon
description: Story about attending 2017 Big Contest
---

# Presentation
---
<iframe src="//www.slideshare.net/slideshow/embed_code/key/swL9Na1pe2w2ya" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>

<br>

# Introduction
---
> 빅콘테스트 공식 홈페이지 : <http://contest.kbig.kr/>

2016년 아무것도 모른채 참가했던 빅콘테스트에, 1년 후 다시 한 번 참가했다. 1년 사이 많은 변화가 있었다. 2016년 대회를 계기로 데이터 과학에 관심을 가지고 학회에 들어가게 되었고, 분석 프로세스 및 프로그램 사용법들을 익히게 되었다. 그동안 쌓은 지식과 실력을 테스트해 볼 수 있는 좋은 기회라고 생각했다. 

이번 글은 대회 내용에 집중하여 정리해보고자 한다. 다만 대회 정책상 데이터를 외부로 공개할 수가 없어, 구체적인 분석 내용들을 공유할 수 없음이 아쉬울 따름이다. 개인적으로 이번 대회는 대회 운영 방식에서 실망스러운 부분이 많았고 앞으로는 참여할 생각이 없다. 하지만 혹시 빅콘테스트에 참여하려는 사람이 있다면, 이 글이 조금이나마 도움이 되었으면 좋겠기에, 대회에 관련된 몇가지 팁도 마지막에 남겨본다.

<br>

# Project Report
---
## 1. 프로젝트 목표

대출한 사람의 **금융 데이터**(신용평가원) + **통신 데이터**(SKT) + **보험 데이터**(한화생명)을 이용하여 고객의 대출 연체 여부를 예측하는 프로젝트
- 대출 연체 예측 알고리즘 개발
- 가장 높은 F1 Score 기록하기

## 2. 프로젝트 특징
 
### 1) 비식별화 된 데이터

독립적인 세 개 회사의 데이터를 융합하여 제공하는 과정에서, 고객 정보에 대한 **비식별화** 작업이 이루어졌다. 때문에 원래 데이터가 가지고 있던 많은 정보가 손실되어, 좋은 모델 성능을 끌어내는데에 한계가 생길 수 밖에 없었다.

> #### **비식별화란?**
> 기업이 보유한 고객 개인정보의 가공, 삭제, 마스킹 처리 등을 통해 개인을 식별할 수 없도록 하는 기술적인 조치. 비식별화 이후 다른 정보와의 결합을 통해 **재식별이 불가능한 상태**를 말함.

### 2) 매우 불균형한 타겟 변수

타겟 변수인 **대출 연체 여부 (1 또는 0)** 의 불균형이 매우 심했다.  대출 연체자를 의미하는 1의 비율이 전체 데이터 중 4%에 불과했다. 이러한 타겟 변수의 불균형은 매우 심각한 모델 성능의 저하를 유발하는데, 예를 들어 모델이 그냥 모든 Test Set에 대해 0이라고 예측해버려도 Precision이 96%에 육박하게 된다. 또한 Test Set의 약 2000개 데이터 중 확률적으로 80명 정도가 대출 연체자로 예상되는데, 이 수가 매우 적기 때문에 F1 Score가 큰 분산을 가질 수 밖에 없다. (겨우 한 두명의 예측 성공 실패 여부에 따라 점수가 크게 변한다.) 즉, Target Imbalance로 인해 우리는 다음과 같은 두 가지 문제를 해결해야했다.

- Target Imbalance로 인한 모델 성능 저하를 어떻게 막을 것인가?
- 어떻게 안정적으로 Test Set에 대한 F1 Score를 도출할 것인가? 

지나고보니 (본선에서 발표하며 피드백을 받아보니) 이 질문들이 결국 이번 대회의 핵심 포인트였으며, 이에 대한 해결 방안을 뒤에 이어서 이야기 해보려 한다.

## 3. 프로젝트 과정

### 1) 데이터 탐색

변수들을 다양한 시각화로 나타내며 데이터를 이해해나갔다. '신용등급이 떨어진 사람이라면 상환 확률이 낮지 않을까?', '소득대비 많은 돈을 빌린 사람일수록 상환 확률이 낮지 않을까?' 와 같은 질문을 던지고 가설을 세우며, 시각화를 이용해 확인해 나갔다. 그리고 이러한 탐색을 통한 정보들은 파생 변수를 생성할 때 유용하게 사용할 수 있었다.

### 2) 피쳐 엔지니어링

지난 공모전에서 파생변수를 잘 만들어 모델의 성능을 엄청나게 끌어올렸던 경험이 있었기에, 이번에도 좋은 파생변수를 만들기 위해 많은 시간을 투자했다. 그러나 결과적으로 말하면 효과가 없었다. 기존 80개 정도의 변수를 가지고 약 90여개의 파생변수를 만들어봤다. 사실상 만들 수 있는건 다 만들어 본 것 같다. 그러나 크게 모델 성능을 끌어올리는 변수는 없었다. 우리가 찾지 못한 것일 수도 있겠다고 생각했지만 본선에서 다른 팀들의 발표를 들어보니, 유의한 파생 변수를 발견했다고 말하는 팀은 없었다. 즉, 데이터의 정보의 질(?)이 낮다고 볼 수 있겠다. 때문에 우리는 변수를 만들기보단 모델링에 집중하기로 했다.

### 3) 모델링

위에서 말했듯 데이터 자체가 정보를 많이 가지고 있지 못했기 때문에, 최대한 좋은 모델을 만들어서 어떻게든 F1 Score를 끌어올려야 했다. 또한 동시에 위에서 언급한 Target Imbalance의 문제도 해결해야 했다. 먼저 모델로서는 유명한 앙상블 (여기에서 앙상블이라 함은 랜덤 포레스트와 같은 모델 내부에서의 앙상블이 아닌, 독립적인 모델들 간의 앙상블을 뜻한다.) 기법 중 하나인 Stacking Model을 이용했다. Stacking의 자세한 내용에 대해선 [다음](http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/) 글을 참고하시라. 우리의 모델 구조는 다음과 같다.

![](/assets/post_images/2018-01-19-bigcon2/slide1.png)
![](/assets/post_images/2018-01-19-bigcon2/slide2.png)

모델링 과정에서 Target Imbalance를 해결하기 위한 여러 방법들을 시도했다. 흔히 유명하게 알려진 방법으로는 **Threshold를 조정**하는 방법, 또는**Over-Sampling, Under-Sampling, 그리고 SMOTE** 등과 같은 Resampling 기법들이 있다. 또 찾아보니 이외에도 [많은 방법들](https://svds.com/learning-imbalanced-classes/)이 제시되고 있었다. 하지만 결과적으로 이러한 방법들은 그다지 큰 효과를 거두지 못했고, 원본 데이터를 그대로 사용하는 것이 가장 좋은 성능을 보였다. 왜 효과가 없었는지에 대해서는 답하지 못하겠다. Target Imbalance라는 주제는 언젠가 꼭 한 번 깊이 다뤄보고싶다.

 다시 모델 자체로 돌아와보자. 위에 제시된 모델링 과정에서 2계층 모델이 가장 좋은 성능을 보였다. 그러나 우리의 모델에는 큰 문제가 있었다. 그건 바로 실제로 제출해야 하는 **Test Set과 우리의 Validation Set의 환경이 매우 다르다는 것**이었다. 모델링 과정에서 5 fold Cross Validation을 수행했는데, 이 때 Validation Set은 약 20000명의 데이터를 가지고 있었다. 그러나 Test Set은 겨우 2000명의 데이터만을 가지고 있었기에 모델링의 결과를 도저히 신뢰할 수가 없었다. **Cross Validation 등을 수행할 때에, Test Set과 유사한 Validation Set을 이용해야 한다**는 것은 이번 대회에서 가장 크게 배운 점 중에 하나이다. 

![](/assets/post_images/2018-01-19-bigcon2/slide3.png)

실제로 Test Set과 비슷한 Validation Set 환경을 만들기위해 49 fold Cross Validation을 수행한 결과, F1 Score가 매우 크게 요동치는 것을 확인했다. 이에 대한 대책이 필요했다. 같은 팀 조장 형이 좋은 아이디어를 냈다. 바로 Validation Set과 Test Set의 유사도를 계산하는 것이다. 자세한 내용은 PPT Slide에서 확인할 수 있다. 실제로 이러한 아이디어는 본선 심사에서 심사위원들의 좋은 평가를 받았으며, 수상을 하는데에 큰 기여를 했다.

## 4. 프로젝트 결과

- 챌린지리그 한국빅데이터포럼의장상

## 5. 나의 역할

- 시각화를 통한 EDA 수행
- EDA 결과들을 바탕으로 여러 파생변수 생성
- MissForest 알고리즘을 이용한 결측치 처리
- Target Imbalance 해결을 위한 모델링 실험

<br>

# Tips for Big-Con
---
- **EDA를 충실히 수행해라** : 2016년 대회의 경우, 심사위원들이 EDA를 수행했는지에 대해 엄밀히 질문했다. 2017년에는 대부분의 팀이 기본적으로 EDA를 꽤 열심히 수행했으니, 기본 중의 기본이라 할 수 있다. 즉, 쉽게 말해 그냥 모델에 때려박지 않고 데이터에 대해 충분히 이해했다는 것을 어필해야한다. 

- **외부 변수를 끌어다써라** : 모델의 성능 향상 여부와 관계없이 외부 데이터를 결합시키는 것에 대해 좋은 평가를 내리는 분위기다. 끌어다 붙일 수 있는 여지가 있는 외부 데이터가 있다면 무조건 갖다써라.

- **홈페이지 질문 게시판을 주시해라** : 빅콘 홈페이지에는 대회가 시작되면 질문 게시판이 활성화된다. 많은 팀들이 질의응답을 주고 받는 과정을 지켜보기만 해도 꽤 많은 아이디어를 얻을 수 있다.

- **왠만하면 같은 분석 언어를 사용하는 사람과 같이 해라** : 크게 R과 Python 유저로 나뉠텐데, 아무리 서로의 언어를 이해할 수 있다고 해도 분석 환경이 다르면 여러모로 귀찮은 점이 많다.

당장 생각나는 건 이정도인데, 떠오르는 것들이 더 있다면 계속해서 추가해보도록 하겠다.
